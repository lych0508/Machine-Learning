{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4Li-Yichen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1KAJZPJb8V",
        "colab_type": "text"
      },
      "source": [
        "# HW 4: Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKT4vSn4Jb8W",
        "colab_type": "text"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCK_22g1Jb8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUOc5CSNJb8Z",
        "colab_type": "text"
      },
      "source": [
        "## Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x6ztOSBJb8a",
        "colab_type": "code",
        "outputId": "0d2f1636-d28d-45cd-91bd-c2ebc57c0fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Load Iris dataset and find out what is in this dataset\n",
        "iris = datasets.load_iris()\n",
        "for key, value in iris.items():\n",
        "    print(key)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\n",
            "target\n",
            "target_names\n",
            "DESCR\n",
            "feature_names\n",
            "filename\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfVlA1k_Jb8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#what's in each of \n",
        "# target_names\n",
        "# DESCR\n",
        "# target\n",
        "# feature_names\n",
        "# data\n",
        "# DESCR and target are shown below. \n",
        "# Continue to work out the rest by appending more cells below."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FdJfmQjplpI",
        "colab_type": "code",
        "outputId": "623c3bc4-f07a-468e-c381-7e0f60d3bb3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2567
        }
      },
      "source": [
        "#See what is in data\n",
        "iris['data']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heVUe1h9qKVk",
        "colab_type": "code",
        "outputId": "b5edfd3b-70eb-4f0e-f99b-2ebc98f740d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#See what is in target names\n",
        "iris['target_names']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7HHRyCTJb8h",
        "colab_type": "code",
        "outputId": "c27aacda-9213-4c95-fec3-d2589024b0bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Let's see the description of this dataset?\n",
        "iris['DESCR']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI5FRDwwpapp",
        "colab_type": "code",
        "outputId": "51a60588-c557-4d4d-b8cb-3f00a285b9d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#See feature names\n",
        "iris['feature_names']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XagvrOvqc9s",
        "colab_type": "code",
        "outputId": "f6fc9e4c-4ea1-41ae-d117-4deff8373607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#See filepath\n",
        "iris['filename']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.6/dist-packages/sklearn/datasets/data/iris.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFoAEceiJb8k",
        "colab_type": "code",
        "outputId": "5d947172-a270-4367-91f8-1e93c078366b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#What's in target?\n",
        "iris['target']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saCkrYTAJb8m",
        "colab_type": "code",
        "outputId": "1991520d-0640-49b9-fa1a-5a3cea20cf84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#How many 0s, 1s, and 2s are in target?\n",
        "import collections, numpy\n",
        "collections.Counter(iris['target'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 50, 1: 50, 2: 50})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX9IV8V3Jb8o",
        "colab_type": "text"
      },
      "source": [
        "## Using Logistic Regression for binary class classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LukyzUE5Jb8p",
        "colab_type": "code",
        "outputId": "d9c2e024-83fe-4b3f-8def-1445e0109745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Let's focus on data with only two classes ( the first 100 entries)\n",
        "data_100 = iris.data[:100,:]\n",
        "target_100 = iris.target[:100]\n",
        "target_100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2YtU2h5Jb8r",
        "colab_type": "code",
        "outputId": "c6863e8b-6946-469c-b16e-f26f902bd8b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#check the size of data_100\n",
        "data_100.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ8z4lP5Jb8t",
        "colab_type": "text"
      },
      "source": [
        "## Standardize Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GVzAc0IJb8t",
        "colab_type": "code",
        "outputId": "0a263428-4823-4ab5-a571-eeec8fccc3ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#What's the mean and standard deviation of data_100 and target_100\n",
        "print(\"The mean of data_100 is \", data_100.mean())\n",
        "print(\"The standard deviation of data_100 is \", data_100.std())\n",
        "print(\"The mean of target_100 is \", target_100.mean())\n",
        "print(\"The standard deviation of target_100 is \", target_100.std())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean of data_100 is  3.05425\n",
            "The standard deviation of data_100 is  1.8745617987945877\n",
            "The mean of target_100 is  0.5\n",
            "The standard deviation of target_100 is  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbapNxDAJb8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "# Transform the feature\n",
        "data_100_standardized = scaler.fit_transform(data_100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0FN2nH2Jb8x",
        "colab_type": "code",
        "outputId": "ceff3361-84c7-4378-b564-47a3b49bf892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#what's the mean and standard deviation of the standardized data_100\n",
        "print(\"The mean of data_100_standarized is \", data_100_standardized.mean())\n",
        "print(\"The standard deviation of data_100_standarized is \", data_100_standardized.std())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean of data_100_standarized is  -1.1723955140041654e-15\n",
            "The standard deviation of data_100_standarized is  0.9999999999999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbJ_a8dKJb8z",
        "colab_type": "text"
      },
      "source": [
        "## Create Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVebgMrjJb80",
        "colab_type": "code",
        "outputId": "fb2b649c-0699-4824-a77d-dca34a51f133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Let's create a dataframe table to store all the features\n",
        "features = pd.DataFrame(data_100_standardized, columns=iris.feature_names)\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.581066</td>\n",
              "      <td>0.841837</td>\n",
              "      <td>-1.012978</td>\n",
              "      <td>-1.042111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.894309</td>\n",
              "      <td>-0.207835</td>\n",
              "      <td>-1.012978</td>\n",
              "      <td>-1.042111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.207552</td>\n",
              "      <td>0.212034</td>\n",
              "      <td>-1.082312</td>\n",
              "      <td>-1.042111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.364174</td>\n",
              "      <td>0.002099</td>\n",
              "      <td>-0.943643</td>\n",
              "      <td>-1.042111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.737687</td>\n",
              "      <td>1.051772</td>\n",
              "      <td>-1.012978</td>\n",
              "      <td>-1.042111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
              "0          -0.581066          0.841837          -1.012978         -1.042111\n",
              "1          -0.894309         -0.207835          -1.012978         -1.042111\n",
              "2          -1.207552          0.212034          -1.082312         -1.042111\n",
              "3          -1.364174          0.002099          -0.943643         -1.042111\n",
              "4          -0.737687          1.051772          -1.012978         -1.042111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nqMpRYAJb82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create another dataframe to store the target\n",
        "target = pd.DataFrame(target_100, columns=['target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkh09S56Jb84",
        "colab_type": "code",
        "outputId": "20463579-50d5-4b18-9961-82878baddf91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "# let's combine these two 'tables' into one dataframe\n",
        "df = pd.concat([features,target], axis=1)\n",
        "df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.581066</td>\n",
              "      <td>0.841837</td>\n",
              "      <td>-1.012978</td>\n",
              "      <td>-1.042111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.894309</td>\n",
              "      <td>-0.207835</td>\n",
              "      <td>-1.012978</td>\n",
              "      <td>-1.042111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0          -0.581066          0.841837          -1.012978         -1.042111   \n",
              "1          -0.894309         -0.207835          -1.012978         -1.042111   \n",
              "\n",
              "   target  \n",
              "0       0  \n",
              "1       0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bTtCrOsJb86",
        "colab_type": "code",
        "outputId": "bcd8d1c7-c153-4e07-be6e-8d42744f5444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#find out which is most correlated to the target?\n",
        "df.corr().abs().target.sort_values(ascending=False)[1:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "petal length (cm)    0.969990\n",
              "petal width (cm)     0.960307\n",
              "sepal length (cm)    0.728290\n",
              "sepal width (cm)     0.690684\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr7pi0u23O8J",
        "colab_type": "text"
      },
      "source": [
        "**Petal length is the most correlated to the target**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD8aUMADJb89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create logistic regression object\n",
        "LogReg = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-qUbHPfJb9B",
        "colab_type": "text"
      },
      "source": [
        "## Train Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c9CDomVJb9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create (X,y) data pair ready for fitting the model\n",
        "X = df[iris.feature_names]\n",
        "y=df['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS9I2SnYJb9E",
        "colab_type": "code",
        "outputId": "cda2ed5d-b10b-48ee-d1f7-9b926d7d27da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Train model using the entire dataset\n",
        "LogReg.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuZnNbsCJb9G",
        "colab_type": "code",
        "outputId": "e4f390e6-3199-481a-9645-3646f5cbf91e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Add a column predictions to the df datagrame on the predicted values based on X\n",
        "df['target_pred']=LogReg.predict(X)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "      <th>target_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.581066</td>\n",
              "      <td>0.841837</td>\n",
              "      <td>-1.012978</td>\n",
              "      <td>-1.042111</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.894309</td>\n",
              "      <td>-0.207835</td>\n",
              "      <td>-1.012978</td>\n",
              "      <td>-1.042111</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.207552</td>\n",
              "      <td>0.212034</td>\n",
              "      <td>-1.082312</td>\n",
              "      <td>-1.042111</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.364174</td>\n",
              "      <td>0.002099</td>\n",
              "      <td>-0.943643</td>\n",
              "      <td>-1.042111</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.737687</td>\n",
              "      <td>1.051772</td>\n",
              "      <td>-1.012978</td>\n",
              "      <td>-1.042111</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0          -0.581066          0.841837          -1.012978         -1.042111   \n",
              "1          -0.894309         -0.207835          -1.012978         -1.042111   \n",
              "2          -1.207552          0.212034          -1.082312         -1.042111   \n",
              "3          -1.364174          0.002099          -0.943643         -1.042111   \n",
              "4          -0.737687          1.051772          -1.012978         -1.042111   \n",
              "\n",
              "   target  target_pred  \n",
              "0       0            0  \n",
              "1       0            0  \n",
              "2       0            0  \n",
              "3       0            0  \n",
              "4       0            0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovUo9dvqJb9I",
        "colab_type": "code",
        "outputId": "4ae6281e-f1fa-4622-ea16-77767cf2203c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#What's the score of using the entire dataset to train our Logistic Regression?\n",
        "LogReg.score(X,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qy_MAxTJb9K",
        "colab_type": "code",
        "outputId": "5208e1ed-37c1-4664-e7d3-f4c138dcffc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# probability of each class as validated against X\n",
        "# probability of target =0 (We only need to check 0 and 1 because in target_100, there is only 0 and 1)\n",
        "LogReg.predict_proba(X)[:,0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.89030983e-01, 9.71476553e-01, 9.87612030e-01, 9.82851619e-01,\n",
              "       9.92415445e-01, 9.85775233e-01, 9.90215071e-01, 9.86310757e-01,\n",
              "       9.80490169e-01, 9.80950103e-01, 9.89079877e-01, 9.88172711e-01,\n",
              "       9.80708481e-01, 9.92462406e-01, 9.93644975e-01, 9.95016071e-01,\n",
              "       9.90634595e-01, 9.85628542e-01, 9.79883156e-01, 9.92299470e-01,\n",
              "       9.72302046e-01, 9.87126748e-01, 9.96995157e-01, 9.46480171e-01,\n",
              "       9.83829890e-01, 9.60446635e-01, 9.74027723e-01, 9.86197784e-01,\n",
              "       9.84160376e-01, 9.83066862e-01, 9.75613286e-01, 9.61672872e-01,\n",
              "       9.97565275e-01, 9.96705994e-01, 9.75104177e-01, 9.83754714e-01,\n",
              "       9.83693609e-01, 9.94905807e-01, 9.86188248e-01, 9.84487236e-01,\n",
              "       9.88577237e-01, 8.95621532e-01, 9.91501023e-01, 9.65197792e-01,\n",
              "       9.84666164e-01, 9.67117470e-01, 9.93481891e-01, 9.87868541e-01,\n",
              "       9.90368816e-01, 9.84289760e-01, 4.41608610e-03, 8.84664214e-03,\n",
              "       2.41967133e-03, 8.92325475e-03, 2.64259400e-03, 1.38548240e-02,\n",
              "       7.91138299e-03, 1.05048085e-01, 5.12979343e-03, 2.88765650e-02,\n",
              "       3.03956527e-02, 1.39517308e-02, 8.41511867e-03, 6.61114387e-03,\n",
              "       5.01486108e-02, 6.92492275e-03, 1.48535539e-02, 3.24891436e-02,\n",
              "       9.87093023e-04, 2.42891468e-02, 5.36584651e-03, 1.41444938e-02,\n",
              "       1.18939405e-03, 8.91904214e-03, 9.04389214e-03, 6.15541040e-03,\n",
              "       1.92311823e-03, 1.27145803e-03, 7.05010247e-03, 5.32482673e-02,\n",
              "       2.39864621e-02, 3.46681208e-02, 2.34395426e-02, 1.74977010e-03,\n",
              "       1.90632720e-02, 1.80945078e-02, 3.84758527e-03, 2.13268713e-03,\n",
              "       3.82562708e-02, 1.44973723e-02, 1.59381252e-02, 9.36680533e-03,\n",
              "       1.66131919e-02, 7.48320807e-02, 1.68471911e-02, 3.97933722e-02,\n",
              "       2.40673562e-02, 1.16264979e-02, 1.08404668e-01, 2.09942129e-02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmRrDuCdMzI0",
        "colab_type": "code",
        "outputId": "aaf46d46-62d2-41e5-9513-dea0f469c25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "#Probability of target =1 (We only need to check 0 and 1 because in target_100, there is only 0 and 1)\n",
        "LogReg.predict_proba(X)[:,1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01096902, 0.02852345, 0.01238797, 0.01714838, 0.00758456,\n",
              "       0.01422477, 0.00978493, 0.01368924, 0.01950983, 0.0190499 ,\n",
              "       0.01092012, 0.01182729, 0.01929152, 0.00753759, 0.00635502,\n",
              "       0.00498393, 0.00936541, 0.01437146, 0.02011684, 0.00770053,\n",
              "       0.02769795, 0.01287325, 0.00300484, 0.05351983, 0.01617011,\n",
              "       0.03955337, 0.02597228, 0.01380222, 0.01583962, 0.01693314,\n",
              "       0.02438671, 0.03832713, 0.00243472, 0.00329401, 0.02489582,\n",
              "       0.01624529, 0.01630639, 0.00509419, 0.01381175, 0.01551276,\n",
              "       0.01142276, 0.10437847, 0.00849898, 0.03480221, 0.01533384,\n",
              "       0.03288253, 0.00651811, 0.01213146, 0.00963118, 0.01571024,\n",
              "       0.99558391, 0.99115336, 0.99758033, 0.99107675, 0.99735741,\n",
              "       0.98614518, 0.99208862, 0.89495191, 0.99487021, 0.97112344,\n",
              "       0.96960435, 0.98604827, 0.99158488, 0.99338886, 0.94985139,\n",
              "       0.99307508, 0.98514645, 0.96751086, 0.99901291, 0.97571085,\n",
              "       0.99463415, 0.98585551, 0.99881061, 0.99108096, 0.99095611,\n",
              "       0.99384459, 0.99807688, 0.99872854, 0.9929499 , 0.94675173,\n",
              "       0.97601354, 0.96533188, 0.97656046, 0.99825023, 0.98093673,\n",
              "       0.98190549, 0.99615241, 0.99786731, 0.96174373, 0.98550263,\n",
              "       0.98406187, 0.99063319, 0.98338681, 0.92516792, 0.98315281,\n",
              "       0.96020663, 0.97593264, 0.9883735 , 0.89159533, 0.97900579])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SreTfDySBK4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In df, append the target probability = 1 \n",
        "df['target_pred_prob'] =  LogReg.predict_proba(X)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yla9SoYUJb9L",
        "colab_type": "code",
        "outputId": "030b8c94-c8e4-49de-ae3f-00c632dd3e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "# scatter plot the petal length (cm) against y (the target)\n",
        "# scatter plot on the same plot the petal length (cm) against the predicted probabilities in different color, e.g.,red. \n",
        "# target.sort_values('petal length (cm)', inplace=True)\n",
        "df.sort_values('petal length (cm)', inplace=True)\n",
        "\n",
        "plt.scatter(df['petal length (cm)'], df['target'])\n",
        "plt.scatter(df['petal length (cm)'], df['target_pred_prob'] , color='red')\n",
        "plt.xlabel('The predicted probability of petal length (cm)')\n",
        "plt.ylabel('target')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'target')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcHHWd//FX98xkkslMjklGkkwg\ngQAfORQJVwKEAEFOXS9cRURRUBeRhXVdEWElKKggiIvuD0XEXVYBlRVWIOEQEIGEAAG5Ej+IkHsC\nc+SYI5nJdM/vj6pOOtPHdCZTc/X7+Xjkken6VlV/vt0z9fnWt771rVhXVxciIlJ84gMdgIiIDAwl\nABGRIqUEICJSpJQARESKlBKAiEiRKh3oAApVX9885IcrjR9fwYYNbQMdRp8abnVSfQa/4VanqOtT\nU1MVy1WmM4B+VFpaMtAh9LnhVifVZ/AbbnUayPooAYiIFCklABGRIqUEICJSpJQARESKlBKAiEiR\nUgIQESlSSgAiIkVKCUBEpEhFmgDM7GAz+7uZfSVL2Ulm9qyZLTazf48yDpG+1L4twTsb2mjflujT\n/Ta3dbB8RRPNbR19ul2+eHtb1rhpC4teqaNx05as77ly/SbufvwNVq7ftEvb1jW08OAzK6lraMlZ\nz00t7Vnfc/3qd3jqnqdYv/qdjDL/6xp+c8tC/K9rMsqa1jfyl4eW0LS+MaNszfK3WPTjO1iz/K2s\n79nSuJG3nnqRlsaNGWWta+pYd/f9tK6pyyjr2NzMhpeW0bG5eZfK+losqgfCmNlo4H7gb8DL7v6T\nbuXLgFOAtcATwJfcfVmu/Q2HqSBqaqqor4/+S+1Pw61O+eqTSCb5zWNv8OLr9TRtbqd6TDmH7l/D\nJ07cl5J479tSHZ2dXHP7C6ytbyHZBfEY1NZUcvlnZjKiNPdsLT1tl0gmuW/xKp5+aW1GvEDOuuQr\n6+hMcOnNi2nZ0rk9jspRpVx7wWxGjShjU1s7X73paSrbNjO9YQUrJk6npWIMP/znYxhRGs+5bSLZ\nxVd//DSdiR1/5qUlMX54UbDdNbe/QP26Rsa1NLGxqpqayRO217OlpY1XzzyfI15/hpqWBuorJ/Lc\n/rM4+O5b2dKR4G9nfYmj/rajbMl+s9jvzp9RObKUVz/+BWYuX7S97IUDjubg3/2cjq0dxObMYXr9\nKuIkSRJnRc1edD35JGOrx9KxdSt/PeufOPjlJ5nYXE9DVQ2vvncO777zp9DZSeKYOUxZ/xYlXUkS\nsTjrJu1NydNPUjJiBHXnf4Wpix+jelM9TWNrWD/n/dT89D8AMsrWzD6Rybf+hJIRI3r9+5VvKogo\nE0ApUAZcCjSkJwAz2we43d2PDV9fBrS4+49z7U8JYHAabnXKV587/vg6f3w+swV50uFT+dRJ+/f6\nPa+87VlWv5PZ4t3zXZVc9fkje71dvniBXpU989r6nQ7gKZWjSrnp4uP40tUP8oM7v860+hWUAAlg\nZc10/u2s6yivqsi57daOBJ2JLsq3tTO+tYkNo6tpLyuntCRG7biRvP/uHzPrjSVMbG6goWoiz+x7\nFI+ceRFXfmE2z578j5zxlwcz9vvA+04l2QUffCmz7L5DTqWsNM6pSxdklD142Onsv/I19mlYmVH2\n5sRpVC17hVc+/BlOXHRvRvljR3+Yfd96hb3q/p5RtmryDBoPOYJDH7wro+zFUz8JkLNs6u23ZCwv\nVL4EENlkcO7eCXSaWbbiSUB92ut3gBlRxSKyu9q3JXjx9fqsZS++3sDH5s6gvGzX53RpbutgbX3m\nQRxgbX0LzW0dVFVktv562q5x05ac8b7g9cRyHBLylT2//O2sB3CAli2dvPxGPT/49deY0bhq+/JS\nYEb9Cn7w669xyWdvyrltPJng/Cd+mXGQv23u5zj57pv4hxcf2L7+Hs31fOjF+4nTxZvHT+P9Lz+S\ndb/vf+nh7BUBTnn5YXJV9MSlCykje3tz74aVLHnmZY56/qGs5Uc9u5DyxLasZVPq3qSidXPWstrF\njxHP0cStfeZxOjY3M2JMVfYVdsNgmQ00Z4ZKGT++YlhMAlVT0/df4kAbbnXKVp+6hlaamrP3PW9o\n3krJiDJqJo7e5fda97d6kjn+8JNd0NyRZJ9pmfH0tN26je154s2+vHtZ99b4xtYdB7aqtC6e5oox\nADz/jHNC2sE/3d6Nq6hq20xzxZiM/QKc96fb+Ie/ZB7kSxOdHL/8iaz7PPHVx1j4yFMcmcx+Laas\nK5mznmVdSXIc43Me/FNafnUXFR3Zr31UdOb+bEvoYvzmhqxl1Zvqcx4EqzfV09TUSM2MKXnj6o2B\nSgDrCM4CUmrDZTkNh+lfh1t3CQy/OuWqT2Jbguqqcho3Z/6Bj68aSaJjW68+h6oRceIxsh7M47Gg\nPNt+07frfkCNx2DKuPI88ZYTi5GzrCSZ4EP3/5Sj/v4sNZvrqR9Tw5IZR/L707/I5uatXH/n15lW\nv5ISukgQY2XNNL521nWcvHVtzoNYDDho1SscXLc8Y7+/OvpTnPTaY1m3O+G1xxiVyH5xu2LbFt63\nZX2Od4zOjMrciQUgSZwSMtdJEGPjmIlM3Jx5ZtY0toZ4F0zcnHkBu2lsDduqJ/T67yxfA21AEoC7\nrzCzMWY2HVgDfAA4eyBiESlEeVkJh+5fk7Vv/ND9J/aq+wegqmIEtTWVWfvya2sqs3b/pLbbs3oU\n77/7xxkH1EfOvIgJY0fljHem1QBBP3/35DHTajju9us59MX7t68/afM7fOjF+9lrj0rGLV3C3vUr\ntpeV0sWM+hX88M5LGfedK/LW9bS/PsrMN1/I2O+4jmZGbcveos518E8Zf9hBecvz6SJ710Ou5SmV\n532eLb/+JRXtmTFvKa+gcfwk9lz/ZkbZusn70HjIEUzM0s+/dvaJANnLZp3A1Ai6fyDCBGBmhwE3\nANOBbWZ2JvAH4C13vwe4ALgzXP037v56VLGI9IXUCJkXX29gQ/NWxleN5ND9J25f3luXf2ZmztE8\n+Xzvrd9TleVAfeJhtWxlNp84cV8qRo3g6ZfWZcbb2clxt1+fOeLkguuYeOnTWd/vPS/9mZL67Cfq\n0+vfoqm6Om+8723OTEYAR7+zPO92yVEVlGzJ7AFIVlbCHpPzbptP59S9GLEms8tq24EHE1+3lrKN\nGzK3GTce9tufxNnnwG2ZF2YTZ3+a+BXzWZVjFNDkESN48fygXz/1ub997ElMDkcBdS9bO+sEJt/6\nk4z36SuRjQLqaxoFNDgNtzoVUp/2bQk2tbQztrK81y3/bJrbOljzTgtT35W75b9dWxvVc46kZHXm\nASyx5zSanlwCFRXU1FSxZt3GjHhHX3EpFbfcnLHtlk9+ipG/vYtYMrMLI/UHmKvVvPGXv2LsF84l\n3pl5oThZUkIskci5bb79bv3omYz6/d0ZZW3nf4nWK66i+tgjKFmzOqM8MXky8bq6nPtteHEZ4875\nBCXLlhFLJuiKl5A48EA2LngUOjupPvw9xJt23BuQrJ5A0/OvQGUldHYyev7llD1wPyV1a0lMrmXb\nGR+gdf41EA7dbV1Tx6ZnljJ21mGMnrpzourY3EzrW6sZvfee1M6YstPvXHpZX1z4HZBhoH1NCWBw\nGm51Gir1ib/1JtWzZ2Y/UJeU0LRoKcm99wnqs/Jt4m+vJ7nHJKioyJ88aveEGNkPqDV7EK9/O+cB\ntemhxxn1mzuouO3nGeVtnzqHUXf+iliW401XGHM8kXkxN1lSSqOvYPR111D+wP3E69YSmzqVtlPP\n2H6wzZXM2r54AWVP/ZmyZa9llG078CA2/mlx8KKxgdJlr9F54EEwYeLOK65ZzYjFT9Mx+xiYumdm\nxdvadv5seyHq3zk9ElJkmEnuMYlk7dTsZVOmBgekzk645BKq5xxJ9eyZVM85ktFXXEp83Vria7N3\nx8TXr6PjmDlZy9o/+EEoLcseUFkZSTuA1quvpe2LF5CYUktXLE5iSi1tX7yALed9CfI1NnPd6DRy\nJJSW0nr1tTQ9/RxNi1+A5ctpvfraHS3t+dcE77nnNLpKSkjsOY22L15A6/xr2Pjg42w7+D10xWJB\noonF2Hbwe9j44OM73mPCRDrnzM08+ANM3ZOOj38y+8EfoKKC5N779PrgP9AGyzBQEdkVFRW0n3Ia\nFbf+LKOo/ZRToaKC0VdcCrfcTKqTqmT1qqCl3LmNZO3UrGcAySlTabnmOrrGjqV84QLi69aQnDKV\n9tNOD1rcxKnI0ve95ZzPbT8Itl59La3fvHKnlnF8eWYrPF1sa/bhk7GtW4L9hAfZ7Qfb1rQWc5gg\nur9nqmzjY0/nb+UXMSUAkeGorY3yhQ9kLSp/5BHaTzqFil9mdtW0n3Y6jBmT84DaevX3obSE8gfu\nI163juTkKbSf8cEwOaRJHaxDyWl701VZSawlc7RT1+hKusaPz9rttP1sphDd3nMnqVa+7EQJQGQo\namuj/KGFWYvKH3qQLed8Lnc3z7o1bDn/S1BWmqOVH8p2QM3X2s6nooKtnzw76xnL1rPOhng8az9+\n+2mnD9nulaFACUBksNiFC4rxt9fnPcBDV95unmTt1N4dyFPytbZzaP329yAe334xNzm5lvbUyJlQ\n3oQkfU4JQGSghUMKyxc+QHztGpK1U2k/7YydhhR2l7oInPMAP21v2k87o+dWdS8O5L3Ww9nDbiUk\n6RUlAJEBNnr+5TsdqLdfrCU4KGZVUdHjAb51/jVUjBpB4vf3Dq5Wdb6k058JSZQARAZUvou1CxfQ\n+s0rc7aEUwfynN0mpaXwox/R9C+XqVUtWSkBiAygnvrytw+BzKbQC7JqVUsOuhFMZAAVdENXT4b4\nzUgycJQARHZVWxvxt96Etj6Yojzsy89GQyAlakoAIoXq7GT0FZdmTK1AlsnPdkXrFVcF0xWUlGyf\nF2fbwe+h9Yqr+iZukRyUAEQKlBqtU7J6FbFkcvtondHzL9+9/V59JWWvvrJ9tsxYIkHZq68w+uor\n+yZwkRyUAEQK0cNonV53B0W1X5ECKAGIFKCQ0TqDab8ihVACEClAn4zW6cf9ihRCCUCkEFGN1tEo\nIBlAuhFMpEA93nk7yPYr0hM9ErIfDZXHDe6K4VangurTB48B7K/9DrfvB4ZfnQbykZA6AxDZVVFN\nraApG6Sf6RqAiEiRUgIQESlSSgAiIkVKCUBEpEgpAYiIFCklABGRIqUEICJSpJQARESKlBKAiEiR\nivROYDO7EZgFdAEXu/tzaWUXAp8GEsDz7n5JlLGIiMjOIjsDMLO5wH7uPhs4D7gprWwM8G/AHHc/\nFjjQzGZFFYuIiGSKsgtoHnAvgLsvB8aHB36AjvBfpZmVAhVAU4SxiIhIN1F2AU0Clqa9rg+XbXb3\nrWZ2FfAmsAW4y91fz7ez8eMrKC0tiSzY/lJTUzXQIfS54VYn1WfwG251Gqj69OdsoNunJA3PBL4J\n7A9sBh4zs0Pc/aVcG2/YMPSfjTrcprGF4Vcn1WfwG2516ofpoHOWRdkFtI6gxZ8yBagLfz4AeNPd\nG9y9A3gSOCzCWEREpJsoE8DDwJkAZjYTWOfuqTS3AjjAzEaFrw8H/hZhLCIi0k1kXUDuvsjMlprZ\nIiAJXGhm5wKb3P0eM/sB8LiZdQKL3P3JqGIREZFMkV4DcPdvdFv0UlrZz4CfRfn+IiKSm+4EFhEp\nUkoAIiJFSglARKRIKQGIiBQpJQARkSKlBCAiUqSUAEREipQSgIhIkVICEBEpUkoAIiJFSglARKRI\nKQGIiBQpJQARkSKlBCAiUqSUAEREipQSgIhIkVICEBEpUkoAIiJFSglARKRIKQGIiBQpJQARkSKl\nBCAiUqSUAEREipQSgIhIkVICEBEpUkoAIiJFSglARKRIKQGIiBQpJQARkSJVGuXOzexGYBbQBVzs\n7s+lle0J3AmMAF5w93+KMhYREdlZZGcAZjYX2M/dZwPnATd1W+UG4AZ3PxJImNleUcUiIiKZouwC\nmgfcC+Duy4HxZjYGwMziwBzgD2H5he6+KsJYRESkmyi7gCYBS9Ne14fLNgM1QDNwo5nNBJ5098vy\n7Wz8+ApKS0uiirXf1NRUDXQIfW641Un1GfyGW50Gqj6RXgPoJtbt51rgP4AVwANmdoa7P5Br4w0b\n2qKNrh/U1FRRX9880GH0qeFWJ9Vn8BtudYq6PvmSS5RdQOsIWvwpU4C68OcGYKW7/93dE8CjwEER\nxiIiIt1EmQAeBs4ECLt51rl7M4C7dwJvmtl+4bqHAR5hLCIi0k1kXUDuvsjMlprZIiAJXGhm5wKb\n3P0e4BLgv8ILwq8A90UVi4iIZIr0GoC7f6PbopfSyt4Ajo3y/UVEJDfdCSwiUqR6TABmdnyWZR+O\nJBoREek3ObuAzGw6MAO43sz+Na2oDPgR4U1eIiIyNOW7BjAZ+AQwHfj3tOVJ4KcRxiQiIv0gZwJw\n98XAYjNb4O5q7YuIDDOFXAT+i5ndbWaPA5jZ+Wnj90VEZIgqJAHcAtyetu7r4TIRERnCCkkAZe7+\nB4K+f9z9z9GGJCIi/aGg+wDMbBzBQ10ws4OAUVEGJSIi0SvkTuBvA88Ak83sZWAi8OlIoxIRkcj1\nmADc/XEzOxQ4GGgHXnf3rZFHJiIikeoxAZjZt7Ms6ySYvfN37p6MIjAREYlWIdcAaoBPAuOAKoIp\nnvcEPgX8PLrQREQkSoVcA5gKvM/d2wDMrAL4H3f/kJk9FWl0IiISmULOACanDv4A4c97hS81GkhE\nZIgq5AxgiZktAZ4kuBdgFvA3M/sM8HyUwYmISHQKGQV0oZnNA95HcMbwA2ABMBr4n2jDExGRqBQy\nCuhH7n4JwYPb022OJiQREekPhXQBJczsRGAR0JFaqOGfIiJDWyEXgc8HHgHagM7w37YogxIRkegV\ncg1gbPdlmg5aRGToK+QaQAlwCsEcQADlwOUETwoTEZEhqpBrAL8CxgOHAE8RDAO9MsqgREQkeoVc\nA5jq7qcC7u4fB44Fjog2LBERiVohCSAW/l9qZiPdfSVwUIQxiYhIPyikC+hRM/s6cC/wgpm9RXAT\nmIiIDGGFJICjgNPdPWlmi4A9gG9GG5aIiEQtZwIws7OBbxFM/LbCzFJFI4C66EMTEZEo5bwG4O6/\nBg4EfgPMSft3BHB4v0QnIiKRydsF5O4J4Nze7tzMbiQYNtoFXOzuz2VZ53vAbHc/vrfvIyIiu66Q\nUUC9YmZzgf3cfTZwHnBTlnUOBI6LKgYREcktsgQAzCMYOYS7LwfGm9mYbuvcQHBXsYiI9LNCRgH1\n1iRgadrr+nDZZgAzOxd4AlhRyM7Gj6+gtLSkbyMcADU1VQMdQp8bbnVSfQa/4VangapPlAmgu9QN\nZZhZNfA54CSgtpCNN2xo63mlQa6mpor6+uaBDqNPDbc6qT6D33CrU9T1yZdcouwCWkfQ4k+Zwo7h\noycCNQSPmbwHmBleMBYRkX4SZQJ4GDgTwMxmAuvcvRnA3e929wPdfRbwEeAFd/+XCGMREZFuIksA\n7r4IWBrePXwTcKGZnWtmH4nqPUVEpHCRXgNw9290W/RSlnVWAMdHGYeIiGSKsgtIREQGMSUAEZEi\npQQgIlKklABERIqUEoCISJFSAhARKVJKACIiRUoJQESkSCkBiIgUKSUAEZEipQQgIlKklABERIqU\nEoCISJFSAhARKVJKACIiRUoJQESkSCkBiIgUKSUAEZEipQQgIlKklABERIqUEoCISJFSAhARKVJK\nACIiRUoJQESkSCkBiIgUKSUAEZEipQQgIlKklABERIqUEoCISJEqjXLnZnYjMAvoAi529+fSyk4A\nvgckAAfOd/dklPGIiMgOkZ0BmNlcYD93nw2cB9zUbZVbgDPd/RigCjg1qlhERCRTlF1A84B7Adx9\nOTDezMaklR/m7mvCn+uBCRHGIiIi3USZACYRHNhT6sNlALj7ZgAzmwycDCyIMBYREekm0msA3cS6\nLzCzdwH3AV9298Z8G48fX0FpaUlUsfWbmpqqgQ6hzw23Oqk+g99wq9NA1SfKBLCOtBY/MAWoS70I\nu4MWApe7+8M97WzDhrY+D7C/1dRUUV/fPNBh9KnhVifVZ/AbbnWKuj75kkuUXUAPA2cCmNlMYJ27\np9fyBuBGd38wwhhERCSHyM4A3H2RmS01s0VAErjQzM4FNgEPAZ8B9jOz88NN7nD3W6KKR0REdhbp\nNQB3/0a3RS+l/Vwe5XuLiEh+uhNYRKRIKQGIiBQpJQARkSKlBCAiUqSUAEREipQSgIhIkVICEBEp\nUkoAIiJFSglARKRIKQH0lbY24m+9CW1Df9I6ESkOSgC7q7OT0VdcSvWcI6mePZPqOUcy+opLobNz\noCMTEcmrP58HMCyNnn85FbfcvP11yepV21+3Xn3tQIUlItIjnQHsjrY2yhc+kLWofOECdQeJyKCm\nBLAb4m+vJ752TfaydWuIv72+nyMSESmcEsBuSO4xiWTt1OxlU6aS3GNS1jIRkcFACWB3VFTQftoZ\nWYvaTzsdKir6OSARkcLpIvBuap1/DRD0+cfXrSE5ZSrtp52+fbmIyGClBLC7SktpvfpaWr95JfG3\n1wfdPmr5i8gQoATQVyoqSO69z0BHISJSMF0DGMp097GI7AYlgKFIdx+LSB9QF9Bg1taW9bqC7j4W\nkb6gM4CBlq0bJ9XCP+ZwqmcdSvUxh+9o4evuYxHpI0oA/aGxgdInn4CGhh3L8nTjjP7WZVTccjMl\na9cQ6+qiZO0aKm65mdHfukx3H4tIn1EXUJS2bmXc6fMoXb4MEgkoKWHcAQeyccGjjL76yuzdOJ3b\nGPnbu7LubuRdd9D6r5eSrJ1KyepVGeW6+1hEdoXOACI07vR5lL36CrFEghhAIkHZq68w7tQTKF9w\nf9Ztyh+4n1hLS9ayWEsz8Xfepv2U07KWt59yqu5BEJGCKQEUqqchl2tWM+J3d8Ga1cHrxgZKl72W\nddXS5cuIp9brpucunBgku7IX5VreXapLqrGh53VFZNhSF1C6bKNuOjsZPf9yyhc+QHztGpK1U2k/\n7YxgqofSUmhpofrw9xBvaty+m2T1BDbfdDMkk9nfp6vAA3UWydJSRv72jqxlI397B63f+nbus4As\nXVKdYZcUI0f2OiYRGZqK7wwg36ibbBdkwyGXJatXEUsmt/fVj55/OQDVhx1MSVMjMdj+r6SpkTEX\nnB9J+COeXZyni6iF+MoVObft3iUVS3VJnT4vklhFZHArnjOA8GBetvB+SteupbO2lm2nfYDW+dfk\nHlffuY3yRx7KurvyhQ/Q+tnziG9oyloeb94cTTUm1uRfYeuW7MsbG4KWfxaly5cF3UETJu5mdCIy\nlESaAMzsRmAW0AVc7O7PpZWdBHwXSAAL3P07UcZSceU3qfj5T7e/Llu9mrJbbqZrWwcj/vhw1m1G\nLHyAeF1d1rL46tWMvDv7aJ0oxXu623fkqKyLS5e9FnT7ZJNIULrsNTrnzN3N6ERkKImsC8jM5gL7\nufts4Dzgpm6r3AR8DDgGONnMDowqFtra6Lzn/7IWJf/vPuJr1mYti9XVkYxl/4iS8RjJ8vI+C7FQ\nyeoJbCnN3l/fVjaS5LTpWcs6DzyIZDxXXeJ0HnhQX4UoIkNElNcA5gH3Arj7cmC8mY0BMLN9gCZ3\nX+3uSWBBuH4kOteuo7Ih++iaUU31bKwcn7VsY9UEYl05LuQmkyyrjS5n5fLi2x388eDsH9WjB82j\nri17vM2jxrBiwl5Zy1ZM2IvmUWP6LEYRGRqi7AKaBCxNe10fLtsc/l+fVvYOMCPfzsaPr6C0tKRX\ngdRtmUrDmBr22PxORlnDmBqe3/swPvDSwoyyxfscyeFvPs+k5vqMsvqqGhZ21nDAiNGM62jNKN9U\nOoqxnTn643vQVjqS0Z1bM5eXjeSB+hLePP7zdMVizHpjCROaG2ismsgz+x7FbXM/x2fXt/LeAyZn\nbLvub/XMP+s6rr/z60xrWEVJV5JELM7KiXvxtbOuY35Hkn2mVfUq3pqa3m03WKk+g99wq9NA1ac/\nLwLHelkGwIYNvZ/jJlFaxssHzOaUJZndQC8dMJvfn/wFEvESjvr7s0xsbqChaiJLZhzJPWd8ieSC\nn/EPL2TetPXsfkdx9GF7c94Xb+UXt36RsVubt5dtGlnFeeffwnV3XMqMpsw7dt+s3otYPMY+DSsz\nyt6aOI1Xpx7EP/xlQUbZowedyHFHzuCNhc6tJ5zP/xx7DuNbm9gwupr2sqA7at9Jo6mvb87YtmpE\nnGTZCC4550dUtW1mesMKVkycTnPFGOKxoDzbdj2pqanq1XaDleoz+A23OkVdn3zJJcoEsI6gpZ8y\nBajLUVYbLotEeVkJ/pXL2NqRyDjIr/zKZRxSUsqtrZkH1JMOnMzDoy6iq4uM7R752EVc+e49+M8R\nozjny//DhE31HLz2NV6tPYjGscFIna99+vqgxV2/ghKCq90ra6bztbOuA8jZGk/GS+iKxTnqjSU7\n3jNs4d96SC23P/w6nYku2svKWT9uR2u/tCTG5ImVWT+DqooR1NZUsvqdFporxvDKXu/d8eHXVFJV\nMSKqj19EBqlY127clJSPmR0NXOXu7zezmcBN7n5sWvlrwBnAGmAxcLa7v55rf/X1zbsVaCKZ5DeP\nvcFrr64h9nYdXXtM5qCDp/KJE/cF4DePvcGLrzewoXkr46tGcuj+E/nEifuSSCa55vYXqF/XyLiW\nJjZWVlMzZQKXf2YmI0pLqd+8hUv/3+KM97v2y7PZ2NLB925fmtHivuwzhwHkLBtXOYJL/99iyre1\n75SQrv3ybGrGjKJlawdf/fHTdCZ2fCSlJTF+eNExVI7MfSDv6OzkmttfYG19C8kuiMeCg3+qLr2h\n1tjgNtzqA8OvTv1wBpCzhyWyBABgZt8HjgOSwIXAocAmd7/HzI4DUpPX/6+7X59vX7ubAFLatyXY\n1NLO2MpyystKCi5rbutgzTstTH1X9tby8hWNPPGXdcx93xQOmD5hp7I/PreSh59fzUfm7sfsA/fI\nWnby4Xty0hHTCt4nQF1DCy+90cgh+07I2fLPpqe67Ar9MQ5uw60+MPzqNGwTQF/qqwQwkIbbLy4M\nvzqpPoPfcKvTQCaA4psKQkSu1FgoAAAL4ElEQVREACUAEZGipQQgIlKklABERIqUEoCISJFSAhAR\nKVJKACIiRWrI3AcgIiJ9S2cAIiJFSglARKRIKQGIiBQpJQARkSKlBCAiUqSUAEREipQSgIhIkerP\nZwIXJTObC/wO+Ly7Zzxc2MzOBi4heGjOLe7+i34OsWBmVgb8FzCN4AmXn3P3N7utsw14Om3RPHdP\n9FuQBTKzG4FZQBdwsbs/l1Z2EvBdgjoucPfvDEyUu6aHOq0AVhPUCYIn8K3t7xh3hZkdDPwfcKO7\n/6Rb2VD9jvLVaQX9/B0pAUTIzGYAX2XnA2J6+WjgW8CRQAfwnJnd4+5N/RflLvkUsNHdzzazk4Hv\nAZ/ots4mdz++3yPbBWFS3s/dZ5vZAcBtwOy0VW4CTgHWAk+Y2f+6+7IBCLVgBdQJ4DR3b+n/6HZd\n+LfxY+DRHKsMxe+opzpBP39H6gKKVh3wUWBTjvKjgOfcfZO7byFIFMf0V3C9MA+4J/z5jwzuWPOZ\nB9wL4O7LgfFmNgbAzPYBmtx9tbsngQXh+oNdzjoNUe3A6cC67gVD+DvKWaeBogQQIXdv66H7YxJQ\nn/b6HWBytFHtlu3xhn94XWbW/aHCI83sDjN72sy+2u8RFqb7514fLstWNti/k5R8dUr5qZk9ZWbf\nN7OcjwkcDNy9M2wUZTMkv6Me6pTSr9+RuoD6iJmdD5zfbfGV7v7QLuxm0PxR5qjPUd1eZ4v3a8Cv\nCPqh/2xmf3b35yMIsS/l+9wHzXeyi7rH/S3gQaCJ4EzhY8Dd/R1URIbqd9Rdv39HSgB9xN1vBW7d\nxc3WsXMrrRZ4ps+C2g3Z6mNm/0UQ70vhBeGYu3d02+6naes/CrwHGGwJoPvnPoWguy5bWS2D6JQ9\nj3x1wt1vT/1sZgsIvpehmgCG6neU10B8R+oCGlhLgCPMbJyZVRL0qT85wDHl8zDw8fDnDwKPpxda\n4A4zi5lZKUF9XuvnGAvxMHAmgJnNBNa5ezOAu68AxpjZ9LAOHwjXH+xy1snMxprZQ2nddXOBVwcm\nzN03hL+jnAbqO9J00BEyszOAfwPeTdBnWefuJ5vZN4An3H2xmZ0ZrtMF/Njdfz1wEednZiUEZwX7\nEVzQOtfdV3erz7XAiQTDWv/g7tcMXMS5mdn3geMI4rwQOJRgBNM9ZnYccG246v+6+/UDFOYu6aFO\nFwOfBbYALwIXufug/eM3s8OAG4DpwDaC0T5/AN4aqt9RAXXq9+9ICUBEpEipC0hEpEgpAYiIFCkl\nABGRIqUEICJSpJQARESKlG4EG2TM7DqCyeFGEgzjWxwW/QKYAZS6+xUDFN52ZvYrgvmAHiQYvvrx\nPOt+CrgrnD6ikH2fBFzR15PKmdmfgKvd/Y8Frj+fLJ+3mZ0KHObu14QzOJ4E7Ju27GhgffeZUnsR\n7/XAqQTDbXt9M52ZHQiMdPcX8qwzn+x17QLK3L2zt++f5b1OB55x96bU5+fub/SwzTyCoa0f6+3Q\nSDO7m2DG3SF9z0BfUgIYZNz96wBmNh14Kv0gGP6RDiruvp4dN4flchXwW4Lx6UOeuz9IkPhyLfsc\n8BtgtxIA8BHgA+Hkbru7n7eBnAmgn/0LcAHBlAc9Cm+S/CkwazfHxX8JWGJm7xsqs6JGTQlg6Jka\ntmTeDfzJ3b8CYGbfJbjzdhTwBPD19D8WMzseuBpYCewNbAQ+CVQD9wGvAK+6+3ez7YtgvpVfENye\nvhIYHe53OkGimmpm7wJ+CYwlmNP8QoLksC/wqJl9BDgEuDLc3zbgC+7+lpl9GLgGWAP8LVvFwxb8\nC8DBBJN/fdfd7wynqGgHDDgbmEpww802ghvsvpI2VfAHzezrBNMHfMfd7zKzdwM/AzqBMQRnH6k5\nnGaY2f3h+o+7+1fN7FyCVuun02I7l+BM4H/DOh8Zvs9lqSRuZkcRnC0d2a1eVxDczbqN4O7Pfw4/\no1rgv8zsInd/Nm39TuA7wAlAJcEZwqtm9t6w3mXhv68QnEleBGwys7bw88tV15zCO1T/k+C7rALu\ndPcb0updEn7+KwjmsAH4CcHzCdYTzHPfQHDz0xzg12b2uXC9s8xsDsENUl/Ocob2BeBBd28MYzmP\nIIFsI/hOvhn+DjQABwAHAd8guFv9vQS/nxe4e2P4XZ4P/KinOhcDXQMYevYlOHAfDnzWzCaY2ceB\nWnefGx5c9iU4oHR3GEFiOBpoBM4Nlx8AXBUe/HPt6ySCpHMEcA7Bgby77xE8nONYgomtznH3K8Oy\necBWgpbcR919LsHc6Kk7OH8CnOnup5D/TKHM3U8maNX+yMxSv8Oj3f348AEatwP/4u4nAD8kOHCl\nlIbbfwj4j3D7ScC/u/s8goNv+t3L7w7f6yjgQxY80CMnd78H+AvwrwTTE9Sa2d5h8T+SOb/SbIID\n5hx3nwPUAJ8Ku2LWEzwU5Fl2VkKQrI8Hbga+HS7/NfBP4fIvA7e6+2KCM5MfuPsdPdQ1n4sJppc4\nIfwsPhkmHICjgc8T/H4dAryP4Ps+Mvz3j+Fr3P3mtHqlknJ9+J18O3yf7k4N64CZTQMuDz+v2cAU\nM7NwvT3c/QxgPsF3fmH4/uea2bhwnUfC/Qk6AxiKngr7YzvNrBEYR9ASnB22kCFoge+dZdvXfMcT\nhp4m+EP9A8Hc6h4uz7WvMmBReFbRZmZLsuz/KIIDLu7+BMHZQ7pUy/334d9sCcGU0hOAUWldHY8R\ntNyyeSjc/xth//S7wuWLAMI/9D18x9Ow/gTclbb9I2nbQ3DArQN+YGbXACOAiWnrP+Hu28J9P0/Q\nuiyIu3eZ2a0Eifoq4DSC7rB0R6W/RxjvEcB/97D7VKv9aeDfwrMvA36x43jImLQEmZKvrvmcQHD2\nOTd8PZKgcQDwbGqaYzNbTXBW+T7gyXA69FYze7D7DtP8Kfx/DcHvc3d7EpxBQPDZLE29n7ufG74v\n7Hjw0hpgubtvDMsaCX6PNxKcvU4vpMLFQAlg6Ol+MS5G0P1xSwHzoaQfDGIE3SMQPI0sJeu+zOxr\n7NwyL8my/y7yn1W2A6u6X9w1s4kF7Dulpzp07yOOdVuWzFL2E4IujdvCFv79Pay/K35JkAgfApa4\n++Zu5T3Fm0vqc0it3w60Z7twnpYQIH9d82kHvu3uO81OGXYBZfudjLPzZ5fvuRjp2/c0tXO+37HO\nHD8Xst+ipC6g4eEp4KPhzIiY2bfMbL8s673bzFIPzjgWeHkX9rUMmGXBTJ9VZD4bAIJW+Knhdsea\nWaoV20VwBvE6MDHVjWJmx5nZFwm6oxJpMZ+Up64nhtvuT3BQSX8wCO6+CagL+9tT+0qfYnte2vad\n4fZ7sGPW0k8A5WnrzzWz0rAP/HCCayU9SYb1xd3fIficf0BwDaW7Z4ATLJheOxVfIVOCnxj+fyzw\ncljvFeEIG8xsfzP7Vvd4yF/XfJ4i6MrBzOJm9kMzq86z/l/Z8ftSQfD4xpT0eAqxmuAsAOA5gusr\nqSe4/TacZK1Q0wiuUwhKAMPF7wlOfxeZ2WKCP/JsI1BeA75nZk8RXMi7Pcs6ufb1ELCKYArr29gx\nPDXdvwPHm9mfCR7YfUO4/EGCZwJMAT5N0E3xBMGFzCfCbqVLgHvN7D6C2RBzKTOz/yO42HpRjqGl\nnwGuD7uxvkLQF5zSGW5/D/DP4XvfANxuZg8RHOiazCwV+2sEI3qeBX5X4IicR4CfmdlHw9f/DUxw\n96e6r+juSwi6qJ40s6cJDnZ3FvAeh4bxfoHggnGq3peFn/9/h3FA0KV2pZl9uYe65vOfQEv4O/EM\nwbOh843iWRDW5XmCaxOL2NEqfwi4z4LhsoV4kDCBuPsqgj7+P5rZImCFuy8tcD8QNAjydUcVFc0G\nWiRSo4DCC7RDku3iOP7Bwsz+E3jJ3W/po/31+dj8vmZmY4EPA7eH10L+QND1VEhy676vSoLpkWel\nRgL1MqYJBA2YQz18VkKx0xmASETMbEp4sbySXX9a3FDXTDCUeGl4ZtMI/K43OwrH7P8T8HPbvefk\n/oxgmKkO/iGdAYiIFCmdAYiIFCklABGRIqUEICJSpJQARESKlBKAiEiR+v+T3Mi/dO3BwAAAAABJ\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWB2bwO4Jb9N",
        "colab_type": "text"
      },
      "source": [
        "##  Multi-class classification using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgeHqxlZJb9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Iris dataset again\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3OziXQnJb9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standardize the dataset\n",
        "scaler2 = StandardScaler()\n",
        "\n",
        "# Transform the feature\n",
        "standardized_data = scaler2.fit_transform(iris.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcGxzADEJb9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create dataframes for data and target separately\n",
        "data = pd.DataFrame(standardized_data, columns=iris.feature_names)\n",
        "target = pd.DataFrame(iris.target, columns=['target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTKtlzWRJb9U",
        "colab_type": "code",
        "outputId": "d94ec089-7fff-451a-b1d2-58bf51982c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Combine data and target into one big dataframe tables\n",
        "df2=pd.concat([data, target], axis=1)\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.900681</td>\n",
              "      <td>1.019004</td>\n",
              "      <td>-1.340227</td>\n",
              "      <td>-1.315444</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.143017</td>\n",
              "      <td>-0.131979</td>\n",
              "      <td>-1.340227</td>\n",
              "      <td>-1.315444</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.385353</td>\n",
              "      <td>0.328414</td>\n",
              "      <td>-1.397064</td>\n",
              "      <td>-1.315444</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.506521</td>\n",
              "      <td>0.098217</td>\n",
              "      <td>-1.283389</td>\n",
              "      <td>-1.315444</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.021849</td>\n",
              "      <td>1.249201</td>\n",
              "      <td>-1.340227</td>\n",
              "      <td>-1.315444</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0          -0.900681          1.019004          -1.340227         -1.315444   \n",
              "1          -1.143017         -0.131979          -1.340227         -1.315444   \n",
              "2          -1.385353          0.328414          -1.397064         -1.315444   \n",
              "3          -1.506521          0.098217          -1.283389         -1.315444   \n",
              "4          -1.021849          1.249201          -1.340227         -1.315444   \n",
              "\n",
              "   target  \n",
              "0       0  \n",
              "1       0  \n",
              "2       0  \n",
              "3       0  \n",
              "4       0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCFslN08Jb9Y",
        "colab_type": "code",
        "outputId": "08306798-d49b-4ff0-ff61-1f0cb17cfb73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#check how many different values does target have?\n",
        "df2.target.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    50\n",
              "1    50\n",
              "0    50\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caO0gdVhJb9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a new copy of Logistic Regression class\n",
        "LogRegM = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mX6_rBNJb9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define (X,y) to be used for training the model\n",
        "X2=df2[iris.feature_names]\n",
        "y2=df2['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj4t_R8KJb9e",
        "colab_type": "code",
        "outputId": "e458ff96-4b07-4a6c-ee1f-7847cb05460e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#Fit the model with all the data\n",
        "LogRegM.fit(X2, y2)\n",
        "#Find out how well it scores\n",
        "LogRegM.score(X2,y2)\n",
        "\n",
        "\n",
        "print (\"The logistic regression score is\", LogRegM.score(X2,y2), \"\\n\\n\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The regression score is 0.9266666666666666 \n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgxoDgQ3Jb9g",
        "colab_type": "code",
        "outputId": "5b2ac507-b102-4dfc-c4b8-54eea3a2a6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "#Show which ones (rows) the model fail to predict \n",
        "df2['target_pred']=LogRegM.predict(X2)\n",
        "\n",
        "df2_failed=df2[(df2['target']!=df2['target_pred'])]\n",
        "df2_failed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "      <th>target_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0.674501</td>\n",
              "      <td>0.328414</td>\n",
              "      <td>0.421734</td>\n",
              "      <td>0.395774</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>1.280340</td>\n",
              "      <td>0.098217</td>\n",
              "      <td>0.649083</td>\n",
              "      <td>0.395774</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.553333</td>\n",
              "      <td>0.558611</td>\n",
              "      <td>0.535409</td>\n",
              "      <td>0.527406</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0.068662</td>\n",
              "      <td>0.328414</td>\n",
              "      <td>0.592246</td>\n",
              "      <td>0.790671</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>1.038005</td>\n",
              "      <td>-0.131979</td>\n",
              "      <td>0.705921</td>\n",
              "      <td>0.659038</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>0.189830</td>\n",
              "      <td>0.788808</td>\n",
              "      <td>0.421734</td>\n",
              "      <td>0.527406</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1.038005</td>\n",
              "      <td>0.098217</td>\n",
              "      <td>0.535409</td>\n",
              "      <td>0.395774</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>-1.143017</td>\n",
              "      <td>-1.282963</td>\n",
              "      <td>0.421734</td>\n",
              "      <td>0.659038</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.189830</td>\n",
              "      <td>-1.973554</td>\n",
              "      <td>0.705921</td>\n",
              "      <td>0.395774</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>0.553333</td>\n",
              "      <td>-0.592373</td>\n",
              "      <td>0.762758</td>\n",
              "      <td>0.395774</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>0.310998</td>\n",
              "      <td>-1.052767</td>\n",
              "      <td>1.046945</td>\n",
              "      <td>0.264142</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "51            0.674501          0.328414           0.421734          0.395774   \n",
              "52            1.280340          0.098217           0.649083          0.395774   \n",
              "56            0.553333          0.558611           0.535409          0.527406   \n",
              "70            0.068662          0.328414           0.592246          0.790671   \n",
              "77            1.038005         -0.131979           0.705921          0.659038   \n",
              "85            0.189830          0.788808           0.421734          0.527406   \n",
              "86            1.038005          0.098217           0.535409          0.395774   \n",
              "106          -1.143017         -1.282963           0.421734          0.659038   \n",
              "119           0.189830         -1.973554           0.705921          0.395774   \n",
              "133           0.553333         -0.592373           0.762758          0.395774   \n",
              "134           0.310998         -1.052767           1.046945          0.264142   \n",
              "\n",
              "     target  target_pred  \n",
              "51        1            2  \n",
              "52        1            2  \n",
              "56        1            2  \n",
              "70        1            2  \n",
              "77        1            2  \n",
              "85        1            2  \n",
              "86        1            2  \n",
              "106       2            1  \n",
              "119       2            1  \n",
              "133       2            1  \n",
              "134       2            1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BarmVPux7QRs",
        "colab_type": "code",
        "outputId": "98ee9fc8-d182-4837-e87a-e23651e3b61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Count how many rows failed to predict\n",
        "df2_failed.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZXM0LkGJb9i",
        "colab_type": "code",
        "outputId": "eb3b415b-3a81-4b70-9353-de93ea83f89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Show the predict_proba of those (rows) that the model failed to predict correctly. It should be some 3-column array similar to the following.\n",
        "# array([[ 0.08409726,  0.39751511,  0.51838763],\n",
        "#          ...,\n",
        "#        [ 0.00318901,  0.58149374,  0.41531726]])\n",
        "df2['target_pred_prob_0'] =  LogRegM.predict_proba(X2)[:,0]\n",
        "df2['target_pred_prob_1'] =  LogRegM.predict_proba(X2)[:,1]\n",
        "df2['target_pred_prob_2'] =  LogRegM.predict_proba(X2)[:,2]\n",
        "df2_failed=df2[(df2['target']!=df2['target_pred'])]\n",
        "df2_failed[['target_pred_prob_0', 'target_pred_prob_1', 'target_pred_prob_2']].values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08375487, 0.39784828, 0.51839685],\n",
              "       [0.01978252, 0.44861961, 0.53159786],\n",
              "       [0.07673632, 0.27028352, 0.65298016],\n",
              "       [0.03901089, 0.21106814, 0.74992098],\n",
              "       [0.008308  , 0.36195146, 0.62974054],\n",
              "       [0.17863756, 0.2056876 , 0.61567484],\n",
              "       [0.03196963, 0.45545321, 0.51257715],\n",
              "       [0.01364452, 0.52329445, 0.46306103],\n",
              "       [0.00133352, 0.63614849, 0.36251799],\n",
              "       [0.00822107, 0.53172499, 0.46005393],\n",
              "       [0.00318708, 0.58278946, 0.41402346]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyreoX8-G5Bu",
        "colab_type": "code",
        "outputId": "73d31728-fab6-41df-a5e9-79028633c885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "#Examine the array you obtained in the output of the cell above.\n",
        "\n",
        "df2_failed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "      <th>target_pred</th>\n",
              "      <th>target_pred_prob_0</th>\n",
              "      <th>target_pred_prob_1</th>\n",
              "      <th>target_pred_prob_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0.674501</td>\n",
              "      <td>0.328414</td>\n",
              "      <td>0.421734</td>\n",
              "      <td>0.395774</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.083755</td>\n",
              "      <td>0.397848</td>\n",
              "      <td>0.518397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>1.280340</td>\n",
              "      <td>0.098217</td>\n",
              "      <td>0.649083</td>\n",
              "      <td>0.395774</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.019783</td>\n",
              "      <td>0.448620</td>\n",
              "      <td>0.531598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.553333</td>\n",
              "      <td>0.558611</td>\n",
              "      <td>0.535409</td>\n",
              "      <td>0.527406</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.076736</td>\n",
              "      <td>0.270284</td>\n",
              "      <td>0.652980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0.068662</td>\n",
              "      <td>0.328414</td>\n",
              "      <td>0.592246</td>\n",
              "      <td>0.790671</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.039011</td>\n",
              "      <td>0.211068</td>\n",
              "      <td>0.749921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>1.038005</td>\n",
              "      <td>-0.131979</td>\n",
              "      <td>0.705921</td>\n",
              "      <td>0.659038</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.008308</td>\n",
              "      <td>0.361951</td>\n",
              "      <td>0.629741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>0.189830</td>\n",
              "      <td>0.788808</td>\n",
              "      <td>0.421734</td>\n",
              "      <td>0.527406</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.178638</td>\n",
              "      <td>0.205688</td>\n",
              "      <td>0.615675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1.038005</td>\n",
              "      <td>0.098217</td>\n",
              "      <td>0.535409</td>\n",
              "      <td>0.395774</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.031970</td>\n",
              "      <td>0.455453</td>\n",
              "      <td>0.512577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>-1.143017</td>\n",
              "      <td>-1.282963</td>\n",
              "      <td>0.421734</td>\n",
              "      <td>0.659038</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.013645</td>\n",
              "      <td>0.523294</td>\n",
              "      <td>0.463061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.189830</td>\n",
              "      <td>-1.973554</td>\n",
              "      <td>0.705921</td>\n",
              "      <td>0.395774</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001334</td>\n",
              "      <td>0.636148</td>\n",
              "      <td>0.362518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>0.553333</td>\n",
              "      <td>-0.592373</td>\n",
              "      <td>0.762758</td>\n",
              "      <td>0.395774</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.008221</td>\n",
              "      <td>0.531725</td>\n",
              "      <td>0.460054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>0.310998</td>\n",
              "      <td>-1.052767</td>\n",
              "      <td>1.046945</td>\n",
              "      <td>0.264142</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>0.582789</td>\n",
              "      <td>0.414023</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "51            0.674501          0.328414           0.421734          0.395774   \n",
              "52            1.280340          0.098217           0.649083          0.395774   \n",
              "56            0.553333          0.558611           0.535409          0.527406   \n",
              "70            0.068662          0.328414           0.592246          0.790671   \n",
              "77            1.038005         -0.131979           0.705921          0.659038   \n",
              "85            0.189830          0.788808           0.421734          0.527406   \n",
              "86            1.038005          0.098217           0.535409          0.395774   \n",
              "106          -1.143017         -1.282963           0.421734          0.659038   \n",
              "119           0.189830         -1.973554           0.705921          0.395774   \n",
              "133           0.553333         -0.592373           0.762758          0.395774   \n",
              "134           0.310998         -1.052767           1.046945          0.264142   \n",
              "\n",
              "     target  target_pred  target_pred_prob_0  target_pred_prob_1  \\\n",
              "51        1            2            0.083755            0.397848   \n",
              "52        1            2            0.019783            0.448620   \n",
              "56        1            2            0.076736            0.270284   \n",
              "70        1            2            0.039011            0.211068   \n",
              "77        1            2            0.008308            0.361951   \n",
              "85        1            2            0.178638            0.205688   \n",
              "86        1            2            0.031970            0.455453   \n",
              "106       2            1            0.013645            0.523294   \n",
              "119       2            1            0.001334            0.636148   \n",
              "133       2            1            0.008221            0.531725   \n",
              "134       2            1            0.003187            0.582789   \n",
              "\n",
              "     target_pred_prob_2  \n",
              "51             0.518397  \n",
              "52             0.531598  \n",
              "56             0.652980  \n",
              "70             0.749921  \n",
              "77             0.629741  \n",
              "85             0.615675  \n",
              "86             0.512577  \n",
              "106            0.463061  \n",
              "119            0.362518  \n",
              "133            0.460054  \n",
              "134            0.414023  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK5mLBpg97sv",
        "colab_type": "text"
      },
      "source": [
        "**Do you see your trained model missed to predict the correct target by a lot/little? Explain your observation.**\n",
        "\n",
        "The trained model missed to predict the correct target by a little. There are 11 rows are mispredicted over 150 data. The mispredict rate is around 7%.\n",
        "\n",
        "Moreover, we see the logistic regression score 0.9267 or 0.93. This indicates that it is 93% accurate or has 7% mispredict. This matches our result from above."
      ]
    }
  ]
}